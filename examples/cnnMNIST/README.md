## 使用说明

### 训练

```
python cnnMNIST_train.py
```

### 模型冻结

```
sh freeze.sh
```

### 模型预测

```
python predict.py
```

### 转换fpga需要的verilog项目

```
../../src/LeFlow cnnMNIST_to_fpga.py
```

### 模型仿真

```
cd cnnMNIST_to_fpga_files
make w
```

需要等待几个小时
输出结果可在temp10对应的ram中找到

### tf-model-server模型托管

```
python model_to_serving.py
```

此时在Model目录下生成test/1，版本为1的模型托管pb文件

启动tf-serving服务：

```
docker run -p 8500:8500 -p 8501:8501 -v /root/LeFlow/examples/cnnMNIST/Model/test:/models/mnist -e MODEL_NAME=mnist -e MODEL_BASE_PATH=/models -it tensorflow/serving test-model-serving
```

服务启动了8500的grpc接口和8501的rest api接口，接下来测试restapi接口：

接口组成介绍：

```
POST http://host:port/<URI>:<VERB>

URI: /v1/models/${MODEL_NAME}[/versions/${MODEL_VERSION}]

VERB: classify|regress|predict
```

其中`${MODEL_NAME}`是启动服务传入的环境变量`mnist`，`${MODEL_VERSION}`是模型转换时指定的，这里可以指定具体的模型版本。如果不指定一般都是用最新的模型版本。`VERB`：预测问题一般是predict

获取接口元数据：

```
[root@yangzhenyu ~]# curl -X GET http://localhost:8501/v1/models/mnist/versions/1/metadata
{
"model_spec":{
 "name": "mnist",
 "signature_name": "",
 "version": "1"
}
,
"metadata": {"signature_def": {
 "signature_def": {
  "predict_images": {
   "inputs": {
    "x": {
     "dtype": "DT_FLOAT",
     "tensor_shape": {
      "dim": [
       {
        "size": "-1",
        "name": ""
       },
       {
        "size": "784",
        "name": ""
       }
      ],
      "unknown_rank": false
     },
     "name": "input:0"
    }
   },
   "outputs": {
    "y": {
     "dtype": "DT_FLOAT",
     "tensor_shape": {
      "dim": [
       {
        "size": "-1",
        "name": ""
       },
       {
        "size": "10",
        "name": ""
       }
      ],
      "unknown_rank": false
     },
     "name": "output:0"
    }
   },
   "method_name": "tensorflow/serving/predict"
  }
 }
}
}
}
```

使用post接口做预测：

```
[root@yangzhenyu variables]# curl -X POST http://localhost:8501/v1/models/mnist/versions/1:predict -d '{"signature_nme":"predict_images","inputs":{"keep_prob": 1.0, "x": [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.847058892250061, 0.9960784912109375, 0.10196079313755035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09803922474384308, 0.6078431606292725, 0.9921569228172302, 0.4549019932746887, 0.003921568859368563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02352941408753395, 0.847058892250061, 0.9960784912109375, 0.9960784912109375, 0.06666667014360428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5333333611488342, 0.9960784912109375, 0.9333333969116211, 0.24313727021217346, 0.007843137718737125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27450981736183167, 0.8627451658248901, 0.9333333969116211, 0.21568629145622253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09803922474384308, 0.8705883026123047, 0.988235354423523, 0.32549020648002625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7215686440467834, 0.9960784912109375, 0.529411792755127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27450981736183167, 0.9450981020927429, 0.9647059440612793, 0.16078431904315948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666667014360428, 0.8901961445808411, 0.9960784912109375, 0.4274510145187378, 0.0, 0.0, 0.0, 0.0, 0.011764707043766975, 0.03529411926865578, 0.019607843831181526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.529411792755127, 0.9960784912109375, 0.803921639919281, 0.07450980693101883, 0.0, 0.0, 0.0, 0.545098066329956, 0.760784387588501, 0.9960784912109375, 0.8352941870689392, 0.2392157018184662, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8627451658248901, 0.9960784912109375, 0.20784315466880798, 0.0, 0.0, 0.0, 0.7647059559822083, 0.9960784912109375, 0.9960784912109375, 1.0, 0.9960784912109375, 0.6196078658103943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8588235974311829, 0.9960784912109375, 0.2039215862751007, 0.0, 0.0, 0.545098066329956, 0.9960784912109375, 0.9960784912109375, 0.9294118285179138, 0.2196078598499298, 0.6509804129600525, 0.9921569228172302, 0.20000001788139343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125490203499794, 0.9372549653053284, 0.8666667342185974, 0.01568627543747425, 0.0, 0.011764707043766975, 0.760784387588501, 0.9960784912109375, 0.7490196228027344, 0.19215688109397888, 0.0, 0.5137255191802979, 0.9960784912109375, 0.2039215862751007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2823529541492462, 0.9960784912109375, 0.7843137979507446, 0.0, 0.0, 0.03529411926865578, 0.9960784912109375, 1.0, 0.1882353127002716, 0.0, 0.0, 0.7058823704719543, 0.8705883026123047, 0.02352941408753395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5490196347236633, 0.9960784912109375, 0.4549019932746887, 0.0, 0.0, 0.03529411926865578, 0.9960784912109375, 0.729411780834198, 0.007843137718737125, 0.0, 0.2392157018184662, 0.9764706492424011, 0.5568627715110779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5490196347236633, 0.9960784912109375, 0.33725491166114807, 0.0, 0.0, 0.03529411926865578, 0.9960784912109375, 0.9450981020927429, 0.07450980693101883, 0.03529411926865578, 0.729411780834198, 0.9098039865493774, 0.14901961386203766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3764706254005432, 0.9803922176361084, 0.8000000715255737, 0.02352941408753395, 0.0, 0.007843137718737125, 0.7490196228027344, 0.9960784912109375, 0.4431372880935669, 0.5568627715110779, 0.9960784912109375, 0.5490196347236633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8588235974311829, 0.9960784912109375, 0.49803924560546875, 0.04313725605607033, 0.0, 0.2862745225429535, 0.9725490808486938, 0.9960784912109375, 0.9960784912109375, 0.9960784912109375, 0.458823561668396, 0.24705883860588074, 0.03921568766236305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5921568870544434, 0.988235354423523, 0.9960784912109375, 0.8823530077934265, 0.7215686440467834, 0.7215686440467834, 0.9019608497619629, 0.9843137860298157, 0.960784375667572, 0.960784375667572, 0.9019608497619629, 0.45098042488098145, 0.15294118225574493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4235294461250305, 0.9254902601242065, 0.9960784912109375, 0.9960784912109375, 0.9960784912109375, 0.7725490927696228, 0.2352941334247589, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]}}'
{
    "outputs": [
        [
            9.62639751e-06,
            5.22552509e-05,
            0.000268320204,
            9.64970786e-06,
            0.000707814703,
            1.03732809e-05,
            0.998327792,
            1.99010799e-07,
            0.00061113853,
            2.8554557e-06
        ]
    ]
}
```

这个图片实际显示的是6，这里预测的结果也是6

这里需要注意输入图片要和训练或者前面的元数据维度相同，前面显示是(-1, 784)，-1意味着可以输入多张784维的图片，所以输入格式是：[[784个数据],[784个数据]]

这个例子具体的数组输出可以使用：

```
python output_data.py
```

参考：

```
https://medium.com/@yuu.ishikawa/introduction-to-restful-api-with-tensorflow-serving-9c60969b5b95
https://www.tensorflow.org/tfx/serving/serving_basic
https://www.tensorflow.org/tfx/serving/serving_advanced
https://www.tensorflow.org/tfx/serving/api_rest
https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_saved_model.py
https://www.jianshu.com/p/a9dbf1e63c88?utm_source=oschina-app
https://github.com/tensorflow/serving/blob/46cf87af2e8cd587d1179c72f1b50fd2888e139b/tensorflow_serving/servables/tensorflow/testdata/saved_model_half_plus_two.py
https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_saved_model.py
```
